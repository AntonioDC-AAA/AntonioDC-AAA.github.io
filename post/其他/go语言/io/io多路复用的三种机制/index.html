<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="generator" content="Hugo 0.65.0-DEV" />

  <title>IO多路复用 &middot; Blog</title>

  <meta name="description" content="" />

  
  <meta property="og:locale" content="en-us"/>

  
  <meta property="og:image" content="https://antoniodc-aaa.github.io/images/name.jpg">

  
  <meta property="og:site_name" content="Blog"/>
  <meta property="og:title" content="IO多路复用"/>
  <meta property="og:description" content="IO多路复用的三种机制 IO多路复用（multiplexing）的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或者是写就绪），就能够通知程序进行相应的读写操作
Unix五种IO模型 简述 [1] blocking IO - 阻塞IO [2] nonblocking IO - 非阻塞IO [3] IO multiplexing - IO多路复用 [4] signal driven IO - 信号驱动IO [5] asynchronous IO - 异步IO"/>
  <meta property="og:url" content="https://antoniodc-aaa.github.io/post/%E5%85%B6%E4%BB%96/go%E8%AF%AD%E8%A8%80/io/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%9A%84%E4%B8%89%E7%A7%8D%E6%9C%BA%E5%88%B6/"/>
  <meta property="og:type" content="article"/>
  <meta property="article:published_time" content="0001-01-01T00:00:00Z"/>
  <meta property="article:modified_time" content="0001-01-01T00:00:00Z"/>
  <meta property="article:author" content="Antonio.D.C">
  
  
  

  <script type="application/ld+json">
  {
    "@context" : "http://schema.org",
    "@type" : "Blog",
    "name": "Blog",
    "url" : "https://antoniodc-aaa.github.io/",
    "image": "https://antoniodc-aaa.github.io/images/name.jpg",
    "description": "You only live once !"
  }
  </script>

  
  <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "name": "IO多路复用",
    "headline": "IO多路复用",
    "datePublished": "0001-01-01T00:00:00Z",
    "dateModified": "0001-01-01T00:00:00Z",
    "author": {
      "@type": "Person",
      "name": "Antonio.D.C",
      "url": "https://antoniodc-aaa.github.io/"
    },
    "image": "https://antoniodc-aaa.github.io/images/name.jpg",
    "url": "https://antoniodc-aaa.github.io/post/%E5%85%B6%E4%BB%96/go%E8%AF%AD%E8%A8%80/io/io%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E7%9A%84%E4%B8%89%E7%A7%8D%E6%9C%BA%E5%88%B6/",
    "description": "IO多路复用的三种机制 IO多路复用（multiplexing）的本质是通过一种机制（系统内核缓冲I\/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或者是写就绪），就能够通知程序进行相应的读写操作\nUnix五种IO模型 简述 [1] blocking IO - 阻塞IO [2] nonblocking IO - 非阻塞IO [3] IO multiplexing - IO多路复用 [4] signal driven IO - 信号驱动IO [5] asynchronous IO - 异步IO"
  }
  </script>
  


  <link type="text/css"
        rel="stylesheet"
        href="https://antoniodc-aaa.github.io/css/print.css"
        media="print">

  <link type="text/css"
        rel="stylesheet"
        href="https://antoniodc-aaa.github.io/css/poole.css">

  <link type="text/css"
        rel="stylesheet"
        href="https://antoniodc-aaa.github.io/css/hyde.css">

  
<style type="text/css">
  .sidebar {
    background-color: #fc21803;
  }

  .read-more-link a {
    border-color: #fc21803;
  }

  footer a,
  .content a,
  .related-posts li a:hover {
    color: #fc21803;
  }
</style>



  <link type="text/css" rel="stylesheet" href="https://antoniodc-aaa.github.io/css/blog.css">

  <link rel="stylesheet"
        href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700&display=swap">

  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css"
        integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk="
        crossorigin="anonymous" />

  <link rel="apple-touch-icon-precomposed"
        sizes="144x144"
        href="/apple-touch-icon-144-precomposed.png">

  <link rel="shortcut icon" href="/favicon.png">

  
  </head>
<body>
  <aside class="sidebar">
  <div class="container">
    <div class="sidebar-about">
      
        
        <div class="author-image">
          <img src="https://antoniodc-aaa.github.io/images/name.jpg" class="img-circle img-headshot center" alt="Profile Picture">
        </div>
        
      

      <h1>Blog</h1>

      
      <p class="lead">You only live once !</p>
      
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li>
          <a href="https://antoniodc-aaa.github.io/">Home</a>
        </li>
        <li>
          <a href="/post/"> Posts </a>
        </li><li>
          <a href="/tags/"> Tags </a>
        </li><li>
          <a href="/about/"> About </a>
        </li>
      </ul>
    </nav>

    <section class="social-icons">
      
      <a href="https://github.com/" rel="me" title="GitHub">
        <i class="fab fa-github" aria-hidden="true"></i>
      </a>
      
      <a href="#" rel="me" title="Twitter">
        <i class="fab fa-twitter" aria-hidden="true"></i>
      </a>
      
    </section>
  </div>
</aside>


  <main class="content container">
  <div class="post">
  <h1>IO多路复用</h1>

  <div class="post-date">
    <time datetime="0001-01-01T00:00:00Z">Jan 1, 0001</time> · 2 min read
  </div>

  <h1 id="io多路复用的三种机制">IO多路复用的三种机制</h1>
<p>IO多路复用（multiplexing）的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或者是写就绪），就能够通知程序进行相应的读写操作</p>
<h2 id="unix五种io模型">Unix五种IO模型</h2>
<h3 id="简述">简述</h3>
<p>[1] blocking IO - 阻塞IO
[2] nonblocking IO - 非阻塞IO
[3] IO multiplexing - IO多路复用
[4] signal driven IO - 信号驱动IO
[5] asynchronous IO - 异步IO</p>
<p><strong>前面4种IO都可以归类为synchronous IO - 同步IO，而select、poll、epoll本质上也都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的。</strong></p>
<h3 id="介绍">介绍</h3>
<p>network IO来说，涉及到两个系统对象</p>
<p><strong>application：调用这个IO的进程</strong></p>
<p><strong>kernel：系统内核</strong></p>
<p><img src="https://upload-images.jianshu.io/upload_images/11224747-02876ed5afe356ff.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/552/format/webp" alt="img"></p>
<p><img src="https://upload-images.jianshu.io/upload_images/11224747-e4c17ed342162afc.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/603/format/webp" alt="img"></p>
<p>IO多路复用是网络编程中最常用的模型，最常用的select、epoll都属于这种模型。以select为例：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/11224747-dcc024f7fa2e8460.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/609/format/webp" alt="IO多路复用"></p>
<p>看起来与blocking I/O很相似，两个阶段都阻塞，但是它与blocking I/O的一个重要区别就是它可以等待多个数据报就绪，可以处理多个连接。这里的select相当于一个“代理”。调用select以后进程会被select阻塞，这时，内核空间内select会监听指定的多个datagram（如socket连接），如果其中任意一个数据就绪就返回。这时程序再进行数据读取操作，将数据拷贝至当前进程内。用于select可以监听多个socket，我们可以用它来处理多个连接。</p>
<p><strong>多路复用IO为何比非阻塞IO模型的效率高是因为在非阻塞IO中，不断地询问socket状态是通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程要高的多。</strong></p>
<p>信号驱动IO模型</p>
<p>在信号驱动IO模型中，当用户线程发起一个IO请求操作，会给对应的socket注册一个信号函数，然后用户线程会继续执行，当内核数据就绪时会发送一个信号给用户线程，用户线程接收到信号之后，便在信号函数中调用IO读写操作来进行实际的IO请求操作。</p>
<p>异步I/O<img src="https://upload-images.jianshu.io/upload_images/11224747-05e3a70e98d2331e.gif?imageMogr2/auto-orient/strip%7CimageView2/2/w/572/format/webp" alt="img"></p>
<p>这里面的读取操作的语义与上面的几种模型都不同。这里的读取操作(aio_read)会通知内核进行读取操作并将数据拷贝至进程中，完事后通知进程整个操作全部完成（绑定一个回调函数处理数据）。读取操作会立刻返回，程序可以进行其它的操作，所有的读取、拷贝工作都由内核去做，做完以后通知进程，进程调用绑定的回调函数来处理数据。</p>
<p>在异步IO模型中，IO操作的两个阶段都不会阻塞用户线程，这两个阶段都是由内核自动完成，然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用IO函数进行具体的读写。这点是和信号驱动模型有所不同的，在信号驱动模型中，当用户线程接收到信号表示数据已经就绪，然后需要用户线程调用IO函数进行实际的读写操作；而在异步IO模型中，收到信号表示IO操作已经完成，不需要再在用户线程中调用IO函数进行实际的读写操作。</p>
<h3 id="阻塞非阻塞异步同步总结">阻塞，非阻塞，异步，同步总结</h3>
<ul>
<li>阻塞调用会一直等待远程数据就绪再返回，即上面的<strong>阶段1</strong>会阻塞调用者，直到读取结束。</li>
<li>而非阻塞无论在什么情况下都会立即返回，虽然非阻塞大部分时间不会被block，但是它仍要求进程不断地去主动询问kernel是否准备好数据，也需要进程主动地再次调用recvfrom来将数据拷贝到用户内存。</li>
</ul>
<p>再说一说同步和异步：</p>
<ul>
<li>同步方法会一直阻塞进程，直到I/O操作结束，注意这里相当于上面的<strong>阶段1，阶段2</strong>都会阻塞调用者。其中 Blocking IO - 阻塞IO，Nonblocking IO - 非阻塞IO，IO multiplexing - IO多路复用，signal driven IO - 信号驱动IO 这四种IO都可以归类为同步IO。</li>
<li>而异步方法不会阻塞调用者进程，即使是从内核空间的缓冲区将数据拷贝到进程中这一操作也不会阻塞进程，拷贝完毕后内核会通知进程数据拷贝结束。</li>
</ul>
<p><img src="https://upload-images.jianshu.io/upload_images/11224747-aaabc156a42177d4.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1106/format/webp" alt="img"></p>
<h2 id="linux一些概念">Linux一些概念</h2>
<p>与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不同创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销</p>
<p><strong>进程阻塞</strong>
正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得了CPU资源），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。</p>
<p><strong>缓存I/O</strong>
缓存I/O又称为标准I/O，大多数文件系统的默认I/O操作都是缓存I/O。在Linux的缓存I/O机制中，操作系统会将I/O的数据缓存在文件系统的页缓存中，即数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。</p>
<h3 id="进程阻塞为什么不占用cpu资源">进程阻塞为什么不占用CPU资源</h3>
<p>操作系统添加等待队列只是添加了对这个“等待中”进程的引用，以便在接收到数据时获取进程对象、将其唤醒，而非直接将进程管理纳入自己之下</p>
<h2 id="select">Select</h2>
<h3 id="select-运行机制">select 运行机制</h3>
<p>select()的机制中提供一种<code>fd_set</code>的数据结构，实际上是一个long类型的数组，每一个数组元素都能与一打开的文件句柄（不管是Socket句柄,还是其他文件或命名管道或设备句柄）建立联系，建立联系的工作由程序员完成，当调用select()时，由内核根据IO状态修改fd_set的内容，由此来通知执行了select()的进程哪一Socket或文件可读。</p>
<p>从流程上来看，<strong>使用select函数进行IO请求和同步阻塞模型没有太大的区别，甚至还多了添加监视socket</strong>，以及调用select函数的额外操作，效率更差。但是，使用select以后最大的优势是用户可以在一个线程内同时处理多个socket的IO请求。用户可以注册多个socket，然后不断地调用select读取被激活的socket，即可达到在同一个线程内同时处理多个IO请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p>
<h3 id="select机制的问题">select机制的问题</h3>
<p>1.每次调用select，都需要把<code>fd_set</code>集合从用户态拷贝到内核态，如果<code>fd_set</code>集合很大时，那这个开销也很大</p>
<p>2.同时每次调用select都需要在内核遍历传递进来的所有<code>fd_set</code>，如果<code>fd_set</code>集合很大时，那这个开销也很大</p>
<p>3.为了减少数据拷贝带来的性能损坏，内核对被监控的<code>fd_set</code>集合大小做了限制，并且这个是通过宏控制的，大小不可改变(限制为1024)</p>
<h2 id="poll">Poll</h2>
<p>poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。也就是说，poll只解决了上面的问题3，并没有解决问题1，2的性能开销问题。</p>
<p>poll的函数原型：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">poll</span>(<span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">pollfd</span> <span style="color:#f92672">*</span>fds, nfds_t nfds, <span style="color:#66d9ef">int</span> timeout);

<span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">pollfd</span> {
        <span style="color:#66d9ef">int</span> fd;                         <span style="color:#75715e">// 需要被检测或选择的文件描述符
</span><span style="color:#75715e"></span>        <span style="color:#66d9ef">short</span> events;                   <span style="color:#75715e">// 对文件描述符fd上感兴趣的事件
</span><span style="color:#75715e"></span>        <span style="color:#66d9ef">short</span> revents;                  <span style="color:#75715e">// 文件描述符fd上当前实际发生的事件
</span><span style="color:#75715e"></span>} pollfd_t;
</code></pre></div><p>poll改变了文件描述符集合的描述方式，使用了<code>pollfd</code>结构而不是select的<code>fd_set</code>结构，使得poll支持的文件描述符集合限制远大于select的1024</p>
<h2 id="epoll">Epoll</h2>
<p>epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制</p>
<p>是基于事件驱动的I/O方式，相对于select来说，epoll没有描述符个数限制，使用一个文件描述符管理多个描述符，将用户关心的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-csharp" data-lang="csharp"><span style="color:#66d9ef">int</span> epoll_create(<span style="color:#66d9ef">int</span> size);	<span style="color:#75715e">//创建一个epoll句柄，size表示描述符的数量
</span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> epoll_ctl(<span style="color:#66d9ef">int</span> epfd, <span style="color:#66d9ef">int</span> op, <span style="color:#66d9ef">int</span> fd, <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">epoll_event</span> *<span style="color:#66d9ef">event</span>);
<span style="color:#66d9ef">int</span> epoll_wait(<span style="color:#66d9ef">int</span> epfd, <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">epoll_event</span> * events, <span style="color:#66d9ef">int</span> maxevents, <span style="color:#66d9ef">int</span> timeout);
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-cpp" data-lang="cpp"><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">epoll_event</span> {
    __uint32_t events;  <span style="color:#75715e">/* Epoll events */</span>
    epoll_data_t data;  <span style="color:#75715e">/* User data variable */</span>
};

<span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">union</span> <span style="color:#a6e22e">epoll_data</span> {
    <span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span>ptr;
    <span style="color:#66d9ef">int</span> fd;
    __uint32_t u32;
    __uint64_t u64;
} epoll_data_t;
</code></pre></div><p>epoll是Linux内核为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。</p>
<pre><code>int epoll_create(int size);
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);
</code></pre><p>epoll_ctl()用于向内核注册新的描述符或者改变某个文件描述符的状态。已注册的描述符再内核中会被维护在一颗红黑树中，通过回调函数内核将I/O准备好的描述符加入到一个链表管理，进程会调用epoll_wait()便可以得到事件完成的描述符</p>
<p>epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，进程不需要通过轮询获得事件完成的描述符</p>
<p>epoll比select 和poll 更加灵活并且没有描述符数量限制。</p>
<p>epoll对多线程编程更加友好，一个线程调用了epoll_wait()另一个线程关闭了同一个描述符 ，也不会产生select和poll的不确定情况。</p>
<p>epoll除了提供select/poll那种IO事件的水平触发（Level Triggered）外，还提供了边缘触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。</p>
<ul>
<li>
<p>**水平触发（LT）：**默认工作模式，即当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次通知此事件</p>
</li>
<li>
<p><strong>边缘触发（ET）：</strong> 当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次通知此事件。（直到你做了某些操作导致该描述符变成未就绪状态了，也就是说边缘触发只在状态由未就绪变为就绪时只通知一次）。</p>
<p>这样很大程度上减少了epoll事件被重复触发的次数，因此效率比LT模式高。只支持No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把多个文件描述符的任务饿死。</p>
</li>
</ul>
<p>Epoll作为Linux高性能网络服务器的必备技术，ngix、redis、skynet和大部分游戏服务器使用到这一多路复用技术</p>
<p>服务器需要管理多个客户端连接，而recv只能监视单个socket，epoll的要义是高效监视多个socket</p>
<p>能够预先传入一个socket列表，<strong>如果列表中的socket都没有数据，挂起进程，直到有一个socket收到数据，唤醒进程</strong>。这种方法很直接，也是select的设计思想。</p>
<h3 id="epoll设计思路">EPOLL设计思路</h3>
<h4 id="功能分离">功能分离</h4>
<p>select低效的原因之一是将“维护等待队列”和“阻塞进程”两个步骤合二为一</p>
<p>然而大多数应用场景中，需要监视的socket相对固定，并不需要每次都修改。epoll将这两个操作分开，先用epoll_ctl维护等待队列，再调用epoll_wait阻塞进程。显而易见的，效率就能得到提升。</p>
<h4 id="就绪列表">就绪列表</h4>
<p>select低效的另一个原因在于程序不知道哪些socket收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的socket，就能避免遍历。如下图所示，计算机共有三个socket，收到数据的sock2和sock3被rdlist（就绪列表）所引用。当进程被唤醒后，只要获取rdlist的内容，就能够知道哪些socket收到数据。</p>
<h3 id="未读"><strong>未读</strong></h3>
<p><a href="https://blog.csdn.net/daaikuaichuan/article/details/83862311">https://blog.csdn.net/daaikuaichuan/article/details/83862311</a></p>
<p><a href="http://baijiahao.baidu.com/s?id=1641172494287388070&amp;wfr=spider&amp;for=pc">http://baijiahao.baidu.com/s?id=1641172494287388070&amp;wfr=spider&amp;for=pc</a></p>
<p>(超级好的资料)https://bbs.gameres.com/thread_842984_1_1.html</p>
<h3 id="应用">应用</h3>
<p>epoll_wait范围之后应该是一个循环，遍历所有的事件：</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">int</span> epfd <span style="color:#f92672">=</span> epoll_create(POLL_SIZE);				
    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">epoll_event</span> ev;
    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">epoll_event</span> <span style="color:#f92672">*</span>events <span style="color:#f92672">=</span> NULL;
    nfds <span style="color:#f92672">=</span> epoll_wait(epfd, events, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">500</span>);
    {
        <span style="color:#66d9ef">for</span> (n <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; n <span style="color:#f92672">&lt;</span> nfds; <span style="color:#f92672">+</span><span style="color:#f92672">+</span>n) {
            <span style="color:#66d9ef">if</span> (events[n].data.fd <span style="color:#f92672">=</span><span style="color:#f92672">=</span> listener) {
                <span style="color:#75715e">//如果是主socket的事件的话，则表示
</span><span style="color:#75715e"></span>                <span style="color:#75715e">//有新连接进入了，进行新连接的处理。
</span><span style="color:#75715e"></span>                client <span style="color:#f92672">=</span> accept(listener, (structsockaddr <span style="color:#f92672">*</span>)<span style="color:#f92672">&amp;</span>local, <span style="color:#f92672">&amp;</span>addrlen);
                <span style="color:#66d9ef">if</span> (client <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>) {
                    perror(<span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">accept</span><span style="color:#e6db74">&#34;</span>);		<span style="color:#75715e">//CAD::打印错误
</span><span style="color:#75715e"></span>                    <span style="color:#66d9ef">continue</span>;
                }
                setnonblocking(client);        <span style="color:#75715e">//将新连接置于非阻塞模式
</span><span style="color:#75715e"></span>                ev.events <span style="color:#f92672">=</span> EPOLLIN <span style="color:#f92672">|</span> EPOLLET; <span style="color:#75715e">//并且将新连接也加入EPOLL的监听队列。	
</span><span style="color:#75715e"></span>                <span style="color:#75715e">//注意，这里的参数EPOLLIN|EPOLLET并没有设置对写socket的监听，
</span><span style="color:#75715e"></span>                <span style="color:#75715e">//如果有写操作的话，这个时候epoll是不会返回事件的，如果要对写操作
</span><span style="color:#75715e"></span>                <span style="color:#75715e">//也监听的话，应该是EPOLLIN|EPOLLOUT|EPOLLET
</span><span style="color:#75715e"></span>                ev.data.fd <span style="color:#f92672">=</span> client;
                <span style="color:#66d9ef">if</span> (epoll_ctl(epfd, EPOLL_CTL_ADD, client, <span style="color:#f92672">&amp;</span>ev) <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>) {
                    <span style="color:#75715e">//设置好event之后，将这个新的event通过epoll_ctl加入到epoll的监听队列里面，
</span><span style="color:#75715e"></span>                    <span style="color:#75715e">//这里用EPOLL_CTL_ADD来加一个新的epoll事件，通过EPOLL_CTL_DEL来减少一个
</span><span style="color:#75715e"></span>                    <span style="color:#75715e">//epoll事件，通过EPOLL_CTL_MOD来改变一个事件的监听方式。
</span><span style="color:#75715e"></span>                    fprintf(stderr, <span style="color:#e6db74"></span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">epollsetinsertionerror:fd=%d</span><span style="color:#e6db74">&#34;</span>, client);
                    <span style="color:#66d9ef">return</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>;
                }
            }
            <span style="color:#66d9ef">else</span> <span style="color:#a6e22e">if</span>(event[n].events <span style="color:#f92672">&amp;</span> EPOLLIN)
            {
                <span style="color:#75715e">//如果是已经连接的用户，并且收到数据，
</span><span style="color:#75715e"></span>                <span style="color:#75715e">//那么进行读入
</span><span style="color:#75715e"></span>                <span style="color:#66d9ef">int</span> sockfd_r;
                <span style="color:#66d9ef">if</span> ((sockfd_r <span style="color:#f92672">=</span> event[n].data.fd) <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">0</span>)
                    <span style="color:#66d9ef">continue</span>;
                read(sockfd_r, buffer, MAXSIZE);
                <span style="color:#75715e">//修改sockfd_r上要处理的事件为EPOLLOUT
</span><span style="color:#75715e"></span>                ev.data.fd <span style="color:#f92672">=</span> sockfd_r;
                ev.events <span style="color:#f92672">=</span> EPOLLOUT <span style="color:#f92672">|</span> EPOLLET;
                epoll_ctl(epfd, EPOLL_CTL_MOD, sockfd_r, <span style="color:#f92672">&amp;</span>ev)
            }
            <span style="color:#66d9ef">else</span> <span style="color:#a6e22e">if</span>(event[n].events <span style="color:#f92672">&amp;</span> EPOLLOUT)
            {
                <span style="color:#75715e">//如果有数据发送
</span><span style="color:#75715e"></span>                <span style="color:#66d9ef">int</span> sockfd_w <span style="color:#f92672">=</span> events[n].data.fd;
                write(sockfd_w, buffer, <span style="color:#66d9ef">sizeof</span>(buffer));
                <span style="color:#75715e">//修改sockfd_w上要处理的事件为EPOLLIN
</span><span style="color:#75715e"></span>                ev.data.fd <span style="color:#f92672">=</span> sockfd_w;
                ev.events <span style="color:#f92672">=</span> EPOLLIN <span style="color:#f92672">|</span> EPOLLET;
                epoll_ctl(epfd, EPOLL_CTL_MOD, sockfd_w, <span style="color:#f92672">&amp;</span>ev)
            }
            do_use_fd(events[n].data.fd);
        }
    }
</code></pre></div><p>4个API：epoll_create, epoll_ctl, epoll_wait和close。</p>
<h2 id="总结"><strong>总结</strong></h2>
<table>
<thead>
<tr>
<th align="left"></th>
<th align="center">select</th>
<th align="center">poll</th>
<th align="center">epoll</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">操作方式</td>
<td align="center">遍历</td>
<td align="center">遍历</td>
<td align="center">回调</td>
</tr>
<tr>
<td align="left">底层实现</td>
<td align="center">数组</td>
<td align="center">链表</td>
<td align="center">哈希表</td>
</tr>
<tr>
<td align="left">IO效率</td>
<td align="center">每次调用都进行线性遍历，时间复杂度为O(n)</td>
<td align="center">每次调用都进行线性遍历，时间复杂度为O(n)</td>
<td align="center">事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到readyList里面，时间复杂度O(1)</td>
</tr>
<tr>
<td align="left">最大连接数</td>
<td align="center">1024（x86）或2048（x64）</td>
<td align="center">无上限</td>
<td align="center">无上限</td>
</tr>
<tr>
<td align="left">fd拷贝</td>
<td align="center">每次调用select，都需要把fd集合从用户态拷贝到内核态</td>
<td align="center">每次调用poll，都需要把fd集合从用户态拷贝到内核态</td>
<td align="center">调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝</td>
</tr>
</tbody>
</table>
<h2 id="应用-1">应用</h2>
<p>epoll是Linux目前大规模网络并发程序开发的首选模型。在绝大多数情况下性能远超select和poll。目前流行的高性能web服务器Nginx正式依赖于epoll提供的高效网络套接字轮询服务。但是，在并发连接不高的情况下，多线程+阻塞I/O方式可能性能更好。</p>
<h3 id="1select-应用场景">1.select 应用场景</h3>
<p>select的timeout参数精度为微秒，而poll和epoll为毫秒，因此select更加适用于实时性要求比较高的场景，比如核反应堆的控制</p>
<p>select可移植性比较好，几乎被所有主流平台所支持。epoll仅适用于Linux OS ，只有比较新的系统支持poll</p>
<h2 id="2poll应用场景">2.poll应用场景</h2>
<p>poll没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用poll，而不是select</p>
<h2 id="3-epoll应用场景">3. epoll应用场景</h2>
<p>只需要运行在linux平台上，有大量的描述符需要同时轮询，并且这些链接最好是长连接</p>
<p>需要同时监控小于1000个描述符，就没有必要使用epoll，因为这个场景下并不能体现epoll的优势</p>
<p>需要监控的描述符状态变化多，而且都是非常短暂的，也没必要使用epoll，因为epoll中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过epoll_ctl()进行系统调用</p>

</div>


  </main>

  <footer>
  <div class="copyright">
    &copy; Antonio.D.C 2020 · <a href="https://creativecommons.org/licenses/by-sa/4.0">CC BY-SA 4.0</a>
  </div>
</footer>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/js/all.min.js"
          integrity="sha256-MAgcygDRahs+F/Nk5Vz387whB4kSK9NXlDN3w58LLq0="
          crossorigin="anonymous"></script>

  <script src="https://antoniodc-aaa.github.io/js/blog.js"></script>

  
</body>
</html>
